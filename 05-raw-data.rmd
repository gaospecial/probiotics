# 原始数据处理 {#raw-data}


## 文献数据的预处理

在 WoS 数据库（Core Collection）中检索（2020-12-14）中检索 “probiotic(s)” ，
一共可以得到 37967 条结果，含 ESI 高被引论文 577 篇；
其中，由来源中国的科学家发表的文献数目为 5036 篇，含 ESI 高被引论文 71 篇（图 \@ref(fig:wos-search-result)，[^fn-wos-query]）。

```{r wos-search-result, fig.cap="在 WoS 数据库检索时的结果界面",echo=FALSE}
knitr::include_graphics("figure/wos-search-result.png")
```

[^fn-wos-query]: 由于在 WoS 数据库中，部分来自于台湾、香港等地的论文没有准确标识为中国（China），
所以在设定检索式时做了相应的考虑。

我们从 WoS 数据库下载了下列几个部分的数据：

- #1，即全部的益生菌相关研究文献的官方统计数据概要；
- #2，即全部与益生菌相关研究的高被引论文的完整内容；
- #3，即由中国人发表（含参与）的全部与益生菌相关研究的论文的完整内容；
- #4，即由中国人发表（含参与）的全部与益生菌相关研究的高被引论文的完整内容。

WoS 导出的数据主要由 `bibliometrix` 软件包处理。


```{r}
echo <- knitr::opts_chunk$get("echo")
eval <- knitr::opts_chunk$get("eval")
if (!isTRUE(echo)) knitr::opts_chunk$set(echo = TRUE)
if (isTRUE(eval)) knitr::opts_chunk$set(eval = FALSE)
```


```{r}
highly_cited_export <- "data-raw/probiotic-full-result-highly-cited-record-export.txt"
china_study_export <- "data-raw/probiotic-china-result-record-export.txt"

# in the latest version, convert2df() runs much faster than before
highly_cited <- convert2df(file = highly_cited_export,
                           dbsource = "wos",
                           format = "plaintext")
china_study <- convert2df(file = china_study_export,
                          dbsource = "wos",
                          format = "plaintext")

# there are a few record are duplicated in China result export file,
# we then remove them by UT matching (UT is unique for wos entry)
china_study <- duplicatedMatching(china_study, Field = "UT", exact = TRUE)
```


为每一篇论文加入耳熟能详的影响因子数据。

```{r}
library(dplyr)
file <- "data-raw/2019_Impact_factor.xlsx"
journal_IF <- openxlsx::read.xlsx(file,startRow=3)  %>%
  select(SO,impact_factor) %>%
  mutate(SO=toupper(SO),
         impact_factor=as.numeric(impact_factor)) %>%
  unique() %>%
  mutate(group=cut(impact_factor,
                   breaks = c(-Inf,3,5,10,20,Inf),
                   labels = c("<3",">3",">5",">10",">20")))

highly_cited <- highly_cited %>% left_join(journal_IF)
china_study <- china_study %>% left_join(journal_IF)
```

为了尽可能少的重名，我们使用完整的姓名来区分不同的作者。

```{r}
highly_cited$AU <- highly_cited$AF
china_study$AU <- china_study$AF
```

添加作者国家信息。

```{r}
highly_cited <- metaTagExtraction(highly_cited, Field = "AU_CO")
china_study <- metaTagExtraction(china_study, Field = "AU_CO")

uniq_tag <- function(M, Field = "AU_CO", sep = ";"){
  value <- M[[Field]]
  new_field_name <- paste0(Field, "_NR")
  new_field_value <- unlist(lapply(strsplit(value, split = sep), function(x){
    paste(unique(x), collapse = sep)
  }))
  M[[new_field_name]] <- new_field_value
  return(M)
}

highly_cited <- uniq_tag(highly_cited)
china_study <- uniq_tag(china_study)
```

整合作者单位信息。


```{r}
highly_cited <- uniq_tag(highly_cited, Field = "AU_UN")
china_study <- uniq_tag(china_study, Field = "AU_UN")

```

综上所述，文献数据的预处理包括对 WoS 数据的规范和添加一些辅助信息，
以便为后续的分析打好基础。
预处理后的数据保存下来，供后续使用时调用。

```{r}
saveRDS(highly_cited, file = "data/highly_cited.RDS")
saveRDS(china_study, file = "data/china_study.RDS")
```


## 物种信息的处理

常见的益生菌是各种乳酸菌，在微生物分类学上通常来源于两个属（genus）：
*Bifidobacterium* 和 *Lactobacillus*。但是，并非全部的益生菌都来源于这两个属。

为了尽可能的确定每一篇文献中描述的益生菌来源，我们需要构建一个微生物属名数据库。
经过调研，最终决定依托 ['The All-Species Living Tree' Project （LTP）](https://www.arb-silva.de/projects/living-tree/)来完成。

LTP 维护了现有已知的所有物种名称，因此我们可以从中提取出属名，
在此基础上根据属名的检索结果确定每一个益生菌研究中所用的益生菌的类型。

```{r}
library(ggtree)
library(treeio)

# there is a bug in read.tree, see https://github.com/YuLab-SMU/treeio/pull/41
# 'The All-Species Living Tree' Project 
file_SSU = "data-raw/LTPs132_SSU_tree.newick"
tree_data <- scan(file = file_SSU, 
                  what = "", 
                  sep = "\n", 
                  quiet = TRUE, 
                  encoding = "UTF-8")
tree_data <- gsub(" ","_",tree_data)
tree_data <- paste0(tree_data, collapse = "")
ltp_SSU <- read.tree(text = tree_data)

SSU_file <- "data-raw/LTPs123_LSU_tree.newick"
ltp_LSU <- read.tree(file = SSU_file, skip =  11)
```


```{r eval=FALSE, include=FALSE}
p <- ggtree(ltp, layout = "circular") 
ggsave("figure/ltp-tree.png", plot = p, scale = 2)
```

图 \@ref(fig:ltp-tree) 可以一瞥所有这些物种。不过我们关心的是属名。

```{r ltp-tree, fig.cap="全部物种的进化树"}
knitr::include_graphics("figure/ltp-tree.png")
```

所以，我们从 `tip.label` 中提取物种的信息，并保存到 `organism.Rds` 中。

```{r}
library(tidyr)

prokaryotic_organism <- tibble(ltp = ltp_SSU$tip.label) %>%
  separate(col = ltp, 
           into = c("accession","genus_species","family"),
           sep = "__",
           extra = "drop") %>%
  separate(col = genus_species,
           into = c("genus","species"),
           sep = "_",
           extra = "drop")  # extra is subsp. info
eukaryotic_organism <- tibble(ltp = ltp_LSU$tip.label) %>%
  separate(col = ltp, 
           into = c("genus_species","accession","family"),
           sep = "__",
           extra = "drop") %>%
  separate(col = genus_species,
           into = c("genus","species"),
           sep = "_",
           extra = "drop")  # extra is subsp. info
organism <- rbind(prokaryotic_organism, eukaryotic_organism)

saveRDS(organism, file = "data/organism.Rds")
```

```{r eval=TRUE}
organism <- readRDS("data/organism.Rds")
```


这些物种共有 `r nrow(organism)` 个，
来自于 `r length(unique(organism$genus))` 个不同的属，
`r length(unique(organism$family))` 个不同的科。

## 审查菌种

对文献中的菌种、菌株进行鉴定，是评估菌株特异性研究内容的前提。
粗分成下列几个步骤：

```{r species-workflow, fig.cap=caption_download("获取菌株信息的工作流"), echo = FALSE, eval=TRUE}
DiagrammeR::grViz(
  "digraph {
    graph [layout = dot, rankdir =TB]
    
    node [shape = rectangle]
    rec1 [label = 'Step 1. Locate genus name extract adjacent downstream words']
    rec2 [label = 'Step 2. Resolve genus name']
    rec3 [label = 'Step 3. Resolve species name']
    rec4 [label = 'Step 4. Resolve subsp. or strain name (if possible)']
    
    rec1 -> rec2 -> rec3 -> rec4
  }",
  height = 300
)
```
```{r}
highly_cited <- readRDS("data/highly_cited.RDS")
china_study <- readRDS("data/china_study.RDS")
organism <- readRDS("data/organism.Rds")

organism <- organism %>%
  mutate(species1 = paste(genus, species, sep = " ")) %>%
  mutate(species2 = paste(substr(genus,1,1),"\\. ",species, sep = ""))
genus <- paste0(unique(organism$genus), collapse = "|")
species1 <- paste0(unique(organism$species1),collapse = "|")
species2 <- paste0(unique(organism$species2),collapse = "|")

```


### Step 1

第一步还要细分为以下几个阶段：

- 用全部的物种去匹配，获得菌种的列表

  分成 3 个途径，首先是完整的物种名（如*Bacillus subtilis*，其次是缩写
  （如*B. subtilis*），再次仅使用物种的属名（如*Bacillus*)。
  这一步所得的结果如图 \@ref(fig:content-strain-block) 所示，由图可知，仅使用
  属名搜索发现的覆盖面最广，而使用缩写比全名也要多 200 多个结果，即在 200 多篇
  论文摘要中发现了缩略语形式的物种名称。

- 再用菌种的列表构造新的表达式，去尽可能的获取菌株

```{r}
all_content <- c(highly_cited$AB, china_study$AB)
content_block1 <- str_extract_all(all_content, 
                                 pattern = regex(species1, ignore_case = TRUE))
content_block2 <- str_extract_all(all_content,
                                  pattern = regex(paste0("\\b(",species2,")\\b"),
                                                  ignore_case = TRUE))
content_block3 <- str_extract_all(all_content,
                                  pattern = regex(genus, ignore_case = TRUE))

content_block <- list(r1 = content_block1,
                      r2 = content_block2,
                      r3 = content_block3)

saveRDS(content_block, file = "data/strain-content-block.Rds")
```



```{r content-strain-block, fig.cap=caption_download("3个方法提取物种名的结果"),eval=TRUE}
content_block <- readRDS("data/strain-content-block.Rds")
l <- lapply(content_block, function(x) which(sapply(x, length)>0))
ggVennDiagram(l,category.names = c("full name","abbreviation","only genus")) +
  scale_x_continuous(expand = expansion(mult = 0.1))
```


```{r content-genus-name, fig.cap=caption_download("可见的属名"),eval=TRUE}
genus_found <- table(unlist(content_block$r3))
# hist(genus_found,breaks = 100,ylim = c(0,20))
set.seed(20201223)
ggwordcloud(names(genus_found),as.numeric(genus_found),min.freq = 10,
            random.color = TRUE, fontface = "italic") 
```
图 \@ref(fig:content-genus-name) 展示最常见的几个属；
图 \@ref(fig:content-strain-name) 展示最常见的几个物种。


```{r content-strain-name, fig.cap=caption_download("可见的物种名"),eval=TRUE}
species_found <- table(unlist(content_block$r1))
saveRDS(species_found, file = "data/species-found.Rds")
# hist(genus_found,breaks = 100,ylim = c(0,20))
set.seed(20201223)
ggwordcloud(names(species_found),as.numeric(species_found),min.freq = 10,
            random.color = TRUE,scale = c(2,0.4),
            fontface = "italic") 
```



```{r include=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = echo, 
                      eval = eval)
```